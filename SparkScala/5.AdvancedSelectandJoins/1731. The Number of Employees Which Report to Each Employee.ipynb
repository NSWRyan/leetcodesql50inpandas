{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SLF4J: No SLF4J providers were found.\n",
      "SLF4J: Defaulting to no-operation (NOP) logger implementation\n",
      "SLF4J: See https://www.slf4j.org/codes.html#noProviders for further details.\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spark is ready!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001b[32mimport \u001b[39m\u001b[36m$ivy.$                                      \n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36morg.apache.spark.sql._\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36morg.apache.spark.sql.functions._\n",
       "\n",
       "\u001b[39m\n",
       "\u001b[36mspark\u001b[39m: \u001b[32mSparkSession\u001b[39m = org.apache.spark.sql.SparkSession@3562b6a6"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import $ivy.`org.apache.spark:spark-sql_2.13:3.3.2`\n",
    "import org.apache.spark.sql._\n",
    "import org.apache.spark.sql.functions._\n",
    "\n",
    "val spark = SparkSession.builder()\n",
    "  .appName(\"SparkTest\")\n",
    "  .master(\"local[*]\")\n",
    "  .getOrCreate()\n",
    "spark.sparkContext.setLogLevel(\"ERROR\")\n",
    "  \n",
    "// http://localhost:4040/jobs/\n",
    "println(\"Spark is ready!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[32mimport \u001b[39m\u001b[36mspark.implicits._\n",
       "\n",
       "\u001b[39m\n",
       "defined \u001b[32mclass\u001b[39m \u001b[36mEmployee\u001b[39m\n",
       "\u001b[36memployee\u001b[39m: \u001b[32mSeq\u001b[39m[(\u001b[32mInt\u001b[39m, \u001b[32mString\u001b[39m, \u001b[32mOption\u001b[39m[\u001b[32mInt\u001b[39m], \u001b[32mInt\u001b[39m)] = \u001b[33mList\u001b[39m(\n",
       "  (\u001b[32m9\u001b[39m, \u001b[32m\"Hercy\"\u001b[39m, \u001b[32mNone\u001b[39m, \u001b[32m43\u001b[39m),\n",
       "  (\u001b[32m6\u001b[39m, \u001b[32m\"Alice\"\u001b[39m, \u001b[33mSome\u001b[39m(value = \u001b[32m9\u001b[39m), \u001b[32m41\u001b[39m),\n",
       "  (\u001b[32m4\u001b[39m, \u001b[32m\"Bob\"\u001b[39m, \u001b[33mSome\u001b[39m(value = \u001b[32m9\u001b[39m), \u001b[32m36\u001b[39m),\n",
       "  (\u001b[32m2\u001b[39m, \u001b[32m\"Winston\"\u001b[39m, \u001b[32mNone\u001b[39m, \u001b[32m37\u001b[39m)\n",
       ")\n",
       "\u001b[36memployeesDS\u001b[39m: \u001b[32mDataset\u001b[39m[\u001b[32mEmployee\u001b[39m] = [employee_id: int, name: string ... 2 more fields]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import spark.implicits._\n",
    "\n",
    "case class Employee(employee_id: Int, name: String, reports_to: Option[Int], age: Int)\n",
    "\n",
    "val employee: Seq[(Int, String, Option[Int], Int)] = Seq(\n",
    "  (9, \"Hercy\", None, 43),\n",
    "  (6, \"Alice\", Some(9), 41),\n",
    "  (4, \"Bob\", Some(9), 36),\n",
    "  (2, \"Winston\", None, 37)\n",
    ")\n",
    "\n",
    "val employeesDS = employee.toDF(\"employee_id\", \"name\", \"reports_to\", \"age\").as[Employee]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this problem, we will consider a manager an employee who has at least 1 other employee reporting to them.\n",
    "\n",
    "Write a solution to report the ids and the names of all managers, the number of employees who report directly to them, and the average age of the reports rounded to the nearest integer.\n",
    "\n",
    "Return the result table ordered by employee_id.\n",
    "\n",
    "The result format is in the following example.\n",
    "\n",
    "| employee_id | name  | reports_count | average_age |\n",
    "|-------------|-------|---------------|-------------|\n",
    "| 9           | Hercy | 2             | 39          |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-------+----------+---+\n",
      "|employee_id|   name|reports_to|age|\n",
      "+-----------+-------+----------+---+\n",
      "|          9|  Hercy|      null| 43|\n",
      "|          6|  Alice|         9| 41|\n",
      "|          4|    Bob|         9| 36|\n",
      "|          2|Winston|      null| 37|\n",
      "+-----------+-------+----------+---+\n",
      "\n",
      "+-----------+-----+-------------+-----------+\n",
      "|employee_id| name|reports_count|average_age|\n",
      "+-----------+-----+-------------+-----------+\n",
      "|          9|Hercy|            2|         39|\n",
      "+-----------+-----+-------------+-----------+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001b[36mmanagersDF\u001b[39m: \u001b[32mDataFrame\u001b[39m = [reports_to: int, average_age: int ... 1 more field]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "employeesDS.show()\n",
    "\n",
    "val managersDF = employeesDS.select(\"reports_to\", \"age\").filter(col(\"reports_to\").isNotNull)\n",
    "    .groupBy(col(\"reports_to\"))\n",
    "    .agg(round(avg(col(\"age\")), 0).cast(\"int\").as(\"average_age\"), count(lit(1)).as(\"reports_count\"))\n",
    "\n",
    "managersDF.as(\"a\").join(employeesDS.as(\"b\"), col(\"b.employee_id\") === col(\"a.reports_to\"), \"inner\")\n",
    "    .select(\"employee_id\", \"name\", \"reports_count\", \"average_age\")\n",
    "    .show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Scala (2.13.10)",
   "language": "scala",
   "name": "scala213"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".sc",
   "mimetype": "text/x-scala",
   "name": "scala",
   "nbconvert_exporter": "script",
   "version": "2.13.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
